from argparse import ArgumentParser
from argparse import ArgumentTypeError
import time
import re
import numpy as np
import tarfile
import os
import pysam
import sys
from pysam import VariantFile
import pickle

def str2bool(v):
    if v.lower() in ('yes', 'true', 't', 'y', '1'):
        return True
    elif v.lower() in ('no', 'false', 'f', 'n', '0'):
        return False
    else:
        raise ArgumentTypeError('Please give right flag (True or False).')

Usage = \
"""
python3 phase_variants.py [options] 

Help information can be found by python3 phase_variants.py -h/--help, additional information can be found in \
README.MD or https://github.com/deepomicslab/SpecHLA.
"""
scripts_dir=sys.path[0]+'/'
parser = ArgumentParser(description="SpecHLA",prog='python3 phase_variants.py',usage=Usage)
optional=parser._action_groups.pop()
required=parser.add_argument_group('required arguments')
flag_parser = parser.add_mutually_exclusive_group(required=False)
flag_data = parser.add_mutually_exclusive_group(required=False)
#necessary parameter
required.add_argument("--ref",help="The hla reference file used in alignment",dest='ref',metavar='', type=str)
required.add_argument("-b", "--bam",help="The bam file of the input samples.",dest='bamfile',metavar='')
required.add_argument("-v", "--vcf",help="The vcf file of the input samples.",dest='vcf',metavar='')
required.add_argument("--sa",help="Sample ID",dest='sample_id',metavar='', type=str)
required.add_argument("-s", "--sv",help="Long Indel file after scanindel, we will not consider long InDel \
    if not afforded.",dest='sv',metavar='')
required.add_argument("--gene",help="gene",dest='gene',metavar='', type=str)
required.add_argument("--exon",help="if focus on exon typing.",dest='focus_exon_flag',metavar='',\
 type=int, default=0)
required.add_argument("--fq1",help="fq1",dest='fq1',metavar='', type=str)
required.add_argument("--fq2",help="fq2",dest='fq2',metavar='', type=str)
required.add_argument("--tgs",help="PACBIO TGS fastq",dest='tgs',metavar='', type=str)
required.add_argument("--nanopore",help="NANOPORE TGS fastq",dest='nanopore',metavar='', type=str)
required.add_argument("--hic_fwd",help="fwd_hic.fastq",dest='hic_fwd',metavar='', type=str)
required.add_argument("--hic_rev",help="rev_hic.fastq",dest='hic_rev',metavar='', type=str)
required.add_argument("--tenx",help="10X data",dest='tenx',metavar='', type=str)
required.add_argument("-o", "--outdir",help="The output directory.",dest='outdir',metavar='')
optional.add_argument("--freq_bias",help="freq_bias (default is 0.05)",dest='freq_bias',\
    metavar='',default=0.05, type=float)
optional.add_argument("--snp_dp",help="The minimum depth of SNPs to be considered in HLAtyping\
     step (default is 5).",dest='snp_dp',metavar='',default=5, type=int)
optional.add_argument("--snp_qual",help="The minimum quality of SNPs to be considered in HLAtyping\
     step (default is 0.01).",dest='snp_qual',metavar='',default=0.01, type=float)
optional.add_argument("--indel_len",help="The maximum length for indel to be considered in HLAtyping\
     step (default is 150).",dest='indel_len',metavar='',default=150, type=int)
optional.add_argument("--weight_imb",help="The weight of using phase information of allele imbalance\
 [0-1], default is 0. (default is 0)",dest='weight_imb',metavar='',default=0, type=float)
optional.add_argument("--thread_num",help="thread num.",dest='thread_num',metavar='',default=5, type=int)
optional.add_argument("--use_database",help="Whether use database to link blocks [0,1]. Default is 1.\
     Just used for evaluation",dest='use_database',metavar='',default=1, type=int)
optional.add_argument("--trio",help="The trio infromation; give sample names in the order of child:mother:father.\
 Example: NA12878:NA12891:NA12892. The order of mother and father can be ambiguous.",dest='trio',metavar='', default="None",type=str)

parser._action_groups.append(optional)
args = parser.parse_args()

def if_in_deletion(locus, deletion_region):
    """
    A hete variant can not locate on a deletion region
    Check if the variant is on a deletion region.
    if yes, only keep the major allele in the following scripts
    """
    dele_flag = False
    for deletion in deletion_region:
        if locus >= deletion[0] and locus < deletion[1]:
            dele_flag = True
    return dele_flag

def read_spechap_seq(vcf, snp_list):
    """
    Input: the phased vcf generated by SpecHap; variant loci
    return: the haplotypes at all variant loci
    """
    snp_locus_list = []
    for snp in snp_list:
        snp_locus_list.append(int(snp[1]))
    
    seq_list = [[],[]]
    in_vcf = VariantFile(vcf)
    sample = list(in_vcf.header.samples)[0]
    for record in in_vcf.fetch():
        geno = record.samples[sample]['GT']
        #print (record)
        # if geno == (1,1):
        #     continue
        if record.pos not in snp_locus_list:
            continue
        if sum(geno) == 1 or sum(geno) == 0:
            for i in range(2):
                seq_list[i].append(geno[i])
        else: 
            # print (record, geno)
            for i in range(2):
                seq_list[i].append(geno[i] - 1)

    return seq_list 

def read_vcf(vcffile,outdir,snp_dp,bamfile,indel_len,gene,freq_bias,\
        strainsNum,deletion_region,snp_qual,gene_vcf):
    """
    Filter the small variants, convert the number of ploid to two. 
    Input: the original vcf generated by freebayes -p 3
    Output: the hete variant loci, the gene-specific vcf with two ploids
    """
    snp_index = 1
    snp_index_dict = {}
    record_read_quality ={}
    pysam.index(bamfile)
    samfile = pysam.AlignmentFile(bamfile, "rb")
    if not os.path.exists(outdir):
        os.system('mkdir '+outdir)
    in_vcf = VariantFile(vcffile) # convert vcf to double-allele vcf
    md_vcf = VariantFile(gene_vcf,'w',header=in_vcf.header)
    sample = list(in_vcf.header.samples)[0]
    snp_list, beta_set, allele_set = [], [], []
    for record in in_vcf.fetch():
        if 'DP' not in record.info.keys() or record.info['DP'] <1:
            continue
        geno = record.samples[sample]['GT']    
        depth = record.samples[sample]['AD']
        dp=sum(depth)  
        if record.qual == None:
            print ('WARNING: no vcf quality value.')
            continue
        if record.qual < snp_qual:
            continue
        if record.chrom != gene:
            continue
        if record.chrom == 'HLA_DRB1' and record.pos >= 3898 and record.pos <= 4400:
            continue
        # print (record, dp)
        if dp < snp_dp and args.focus_exon_flag != 1: # depth cutoff for wgs
            continue
        if record.info['DP'] < snp_dp and args.focus_exon_flag == 1: # depth cutoff for wes
            continue 
        # if geno == (0,1,2):
        #     continue
        if len(record.ref) > indel_len:
            continue
        # if len(record.alts) > 2:
        #     continue
        alt_too_long = False
        for alt_allele in record.alts:
            if len(alt_allele) > indel_len:
                alt_too_long = True
        if alt_too_long:
            continue
        if geno == (1,2,3) or geno == (0, 1, 2):
            # if the locus has three alleles, select top two allele or discard this locus.
            norm_depth = np.array(depth)/sum(depth)
            dp_sort=np.argsort(norm_depth)
            max_two_freq = norm_depth[dp_sort[-1]] + norm_depth[dp_sort[-2]]
            alt_genos = []
            fresh_depth = []
            sum_freq = 0
            ref_flag = False
            for i in range(2):
                sum_freq += norm_depth[dp_sort[-(1+i)]]
                if dp_sort[-(1+i)] == 0:
                    ref_flag = True
                if dp_sort[-(1+i)] != 0:
                    alt_genos.append(record.alts[dp_sort[-(1+i)] - 1])
                    fresh_depth.append(depth[dp_sort[-(1+i)]])
            if ref_flag == False :
                star_geno = 1
                fresh_depth = [depth[0]] + fresh_depth
            else:
                star_geno = 0
                fresh_depth = [depth[0]] + fresh_depth
            new_geno = []
            for i in range(2):
                new_geno.append(i + star_geno)
            new_geno.append(new_geno[-1])
            if sum_freq > 0.7:
                # print ('before', record)
                record.alts = alt_genos
                record.samples[sample]['GT'] = tuple(new_geno) 
                record.samples[sample]['AD'] = fresh_depth
                geno = tuple(new_geno) 
            else:
                continue

        snp_index_dict[record.pos] = snp_index
        snp_index += 1

        # if the variant is in deletion region, get consensus haplotype
        if if_in_deletion(record.pos, deletion_region) and geno != (1,1,1):
            if geno == (1,1,2) or geno == (1,2,2):                
                snp = [record.chrom,record.pos,record.alts[0],record.alts[1],record.ref]
            else:
                snp=[record.chrom,record.pos,record.ref,record.alts[0],record.ref]

            reads_list = reads_support(samfile, snp,record_read_quality)
            allele_dp = [len(reads_list[0]), len(reads_list[1])]
            new_dp=sum(allele_dp)
            if new_dp == 0:
                print ('WARNING: the depth of the locus obtained by pysam is zero!',snp)
                continue
            beta=float(allele_dp[1])/new_dp

            if beta <= 1-beta:
                if geno == (1,1,2) or geno == (1,2,2):
                    record.samples[sample]['GT']= tuple([1,1])
                else:
                    record.samples[sample]['GT']= tuple([0,0])
                record.samples[sample].phased=True
            elif beta >= 1 - beta:
                if geno == (1,1,2) or geno == (1,2,2):
                    record.samples[sample]['GT']= tuple([2,2]) 
                else:
                    record.samples[sample]['GT']= tuple([1,1])
                record.samples[sample].phased=True
            md_vcf.write(record)
            continue

        if geno == (1,1,1):
            record.samples[sample]['GT']= tuple([1,1])
            record.samples[sample].phased=True
    
        else:
            if geno == (1,1,2) or geno == (1,2,2):                
                snp = [record.chrom,record.pos,record.alts[0],record.alts[1],record.ref]
            else:
                snp=[record.chrom,record.pos,record.ref,record.alts[0],record.ref]

            reads_list,record_read_quality = reads_support(samfile, snp, record_read_quality)
            allele_dp = [len(reads_list[0]), len(reads_list[1])]
            new_dp = sum(allele_dp)
            # print (record, allele_dp)
            if new_dp == 0:
                print ('WARNING: the depth of the locus obtained by pysam is zero!',snp)
                continue
            beta = float(allele_dp[1])/new_dp # the frequency of alt

            if beta <= freq_bias:
                if geno == (1,1,2) or geno == (1,2,2):
                    record.samples[sample]['GT']= tuple([1,1])
                else:
                    record.samples[sample]['GT']= tuple([0,0])
                record.samples[sample].phased=True
            elif beta >= 1 - freq_bias:
                if geno == (1,1,2) or geno == (1,2,2):
                    record.samples[sample]['GT']= tuple([2,2]) 
                else:
                    record.samples[sample]['GT']= tuple([1,1])
                record.samples[sample].phased=True
            else:
                # each locus has 3 alleles, because freebayes -p 3
                # convert the variant to double allele variant.
                if geno == (1,1,2) or geno == (1,2,2):
                    record.samples[sample]['GT']= tuple([1,2])
                else:
                    record.samples[sample]['GT']= tuple([0,1])
                snp_list.append(snp)
                allele_dp = np.array(allele_dp)
                beta_set.append(allele_dp/new_dp)
        # print ("new", record.samples[sample]['GT'])
        md_vcf.write(record)
    in_vcf.close()
    md_vcf.close()
    os.system('tabix -f %s'%(gene_vcf))
    print ("Num of hete small variant is %s in %s."%(len(snp_list), gene))

    return snp_list, beta_set, snp_index_dict

def freq_output(outdir, gene, fresh_alpha, hete_var_num):
    # output the haplotype frequencies
    ra_file=open(outdir+'/%s_freq.txt'%(gene),'w')    
    print ('# Haplotype\tFrequency',file=ra_file)
    for j in range(len(fresh_alpha)):
        print ('hla.allele.%s.%s.fasta'%(str(j+1), gene),fresh_alpha[j],file=ra_file)
        # print ('str-'+str(j+1),fresh_alpha[j],file=ra_file)
    print ("# The number of heterozygous variant is %s"%(hete_var_num),file=ra_file)
    # print ("# Frequency inference is more reliable with more heterozygotes variants.",file=ra_file)
    ra_file.close()
        
def reads_support(samfile,first,record_read_quality):  
    """
    Input: Bam file, hete variant
    Output: the reads support each allele of the variant 
    """ 
    reads_list=[]
    allele_num=len(first[3])+1
    for i in range(allele_num):
        reads_list.append([])
    num=0
    for read in samfile.fetch(str(first[0]),int(first[1])-1,int(first[1])):
        record_read_quality[read.query_name] = read.mapping_quality
        if int(first[1])-1 in read.get_reference_positions(full_length=True) and read.mapping_quality >1:   
            
            reads_index=read.get_reference_positions(full_length=True).index(int(first[1])-1)
            if first[2][0] != first[3][0]:
                #if the first allele is not same for indel alleles, we can just focus on the first locus 
                if read.query_sequence[reads_index] == first[2][0]:
                    reads_list[0].append(read.query_name)
                elif read.query_sequence[reads_index] == first[3][0]:
                    reads_list[1].append(read.query_name)
            else:  
                index_list=[]
                true_ref=first[4]
                for i in range(len(true_ref)):
                #for i in range(len(first[3])):
                    position=first[1]+i
                    point_flag=isin(position-1,read.get_reference_positions(full_length=True))
                    if point_flag:
                        position_index=read.get_reference_positions(full_length=True).index(position-1)
                        index_list.append(position_index)
                allele_list=read.query_sequence[index_list[0]:index_list[-1]+1].upper()
                ##########for the case that ref is short than alt.#########
                if index_list[-1]+1 < len(read.get_reference_positions(full_length=True)) and len(true_ref) < len(first[2])\
                     and len(true_ref) < len(first[3]) and read.get_reference_positions(full_length=True)[index_list[-1]+1] == None:
                    j = 0
                    # print ('#####', first, allele_list)
                    while index_list[-1]+1+j <  len(read.get_reference_positions(full_length=True)):
                        tag = read.get_reference_positions(full_length=True)[index_list[-1]+1+j]
                        # print (first, tag, type(tag))
                        if read.get_reference_positions(full_length=True)[index_list[-1]+1+j] == None:
                            allele_list+=read.query_sequence[index_list[-1]+1+j]
                        else:
                            break
                        j += 1   
                    # print (first, allele_list)
                ##########for the case that ref is short than alt.#########             
                if allele_list == first[2]:
                    reads_list[0].append(read.query_name)
                elif allele_list == first[3]:
                    reads_list[1].append(read.query_name)
    return reads_list, record_read_quality

def link_reads(samfile,left,right,new_left,snp_index_dict,f,record_read_quality):
    """
    check the reads that support 1/2 indels
    print the reads in a formate same as ExtractHAIRs, which can be recognized by SpecHap
    """
    left_reads=new_left
    right_reads,record_read_quality=reads_support(samfile,right,record_read_quality)
    for i in range(2):
        for j in range(2):
            left_set=left_reads[i]
            right_set=right_reads[j]
            reads_name = set(left_set).intersection(set(right_set))
            for name in reads_name:
                # if len(left[2]) > 1 or len(left[3]) > 1 or len(right[2]) > 1 or len(right[3]) > 1:
                # check if there is one Indel with 1/2 genotype.
                if ((len(left[2]) > 1 or len(left[3]) > 1) and left[2] != left[4]) or\
                     ((len(right[2]) > 1 or len(right[3]) > 1) and right[2] != right[2]):
                    left_index = snp_index_dict[int(left[1])]
                    right_index = snp_index_dict[int(right[1])]
                    left_geno = i
                    right_geno = j
                    # if left[2] != left[4]: # to fit 1/2 
                    #     left_geno += 1
                    # if right[2] != right[4]:
                    #     right_geno += 1

                    if new_formate:
                        print('2 %s 1 -1 -1 %s %s %s %s ?? %s'%(name, left_index, left_geno, right_index, right_geno,record_read_quality[name]), file=f)
                    else:
                        print('2 %s %s %s %s %s ?? %s'%(name, left_index, left_geno, right_index, right_geno,record_read_quality[name]), file=f)
            same_num=len(reads_name)
    return right_reads

def extract_linkage_for_indel(bamfile,snp_list,snp_index_dict,outdir):
    """
    The tool ExtractHAIR of SpecHap can not get linager info for indels with genotype as 1/2
    HLA genes have many 1/2 indels
    This function checks the bam and extract the linkage info for indels to avoid linkage loss
    """
    f = open(outdir + '/fragment.add.file', 'w')
    samfile = pysam.AlignmentFile(bamfile, "rb")
    new_left=''
    record_read_quality = {}
    for i in range(len(snp_list)-1):  
        left=snp_list[i]
        right=snp_list[i+1]  
        if new_left=='':   
            new_left, record_read_quality=reads_support(samfile,left, record_read_quality)
        right_reads=link_reads(samfile,left,right,new_left,snp_index_dict,f,record_read_quality)
        new_left=right_reads
    f.close()

class MNP_linkage():

    def __init__(self, bamfile,snp_list,snp_index_dict,outdir):
        
        self.samfile = pysam.AlignmentFile(bamfile, "rb")   
        self.outdir = outdir
        self.snp_list = snp_list
        self.snp_index_dict = snp_index_dict
        self.read_quality_dict = {}
        self.locus_read_dict = {}
        self.read_cover_geno = {}
        self.discard_reads = {} # discard the reads mapped to the repeat region
        self.get_discard_reads()
    
    def get_sup_reads(self, first, snp_index):
        """
        Input: Bam file, hete variant
        Output: the reads support each allele of the variant 
        """ 
        reads_list=[]
        allele_num=len(first[3])+1
        for i in range(allele_num):
            reads_list.append([])
        num=0
        for read in self.samfile.fetch(str(first[0]),int(first[1])-1,int(first[1])):
            if read.query_name in self.discard_reads:
                continue
            if read.query_name not in self.read_quality_dict:
                self.read_quality_dict[read.query_name] = int(read.mapping_quality)
            if int(first[1])-1 in read.get_reference_positions(full_length=True) and read.mapping_quality >1:   
                
                reads_index=read.get_reference_positions(full_length=True).index(int(first[1])-1)
                if first[2][0] != first[3][0]:
                    #if the first allele is not same for indel alleles, we can just focus on the first locus 
                    if read.query_sequence[reads_index] == first[2][0]:
                        reads_list[0].append(read.query_name)
                    elif read.query_sequence[reads_index] == first[3][0]:
                        reads_list[1].append(read.query_name)
                else:  
                    index_list=[]
                    true_ref=first[4]
                    for i in range(len(true_ref)):
                    #for i in range(len(first[3])):
                        position=first[1]+i
                        point_flag=isin(position-1,read.get_reference_positions(full_length=True))
                        if point_flag:
                            position_index=read.get_reference_positions(full_length=True).index(position-1)
                            index_list.append(position_index)
                    allele_list=read.query_sequence[index_list[0]:index_list[-1]+1].upper()
                    ##########for the case that ref is short than alt.#########
                    if index_list[-1]+1 < len(read.get_reference_positions(full_length=True)) and len(true_ref) < len(first[2])\
                        and len(true_ref) < len(first[3]) and read.get_reference_positions(full_length=True)[index_list[-1]+1] == None:
                        j = 0
                        # print ('#####', first, allele_list)
                        while index_list[-1]+1+j <  len(read.get_reference_positions(full_length=True)):
                            tag = read.get_reference_positions(full_length=True)[index_list[-1]+1+j]
                            # print (first, tag, type(tag))
                            if read.get_reference_positions(full_length=True)[index_list[-1]+1+j] == None:
                                allele_list+=read.query_sequence[index_list[-1]+1+j]
                            else:
                                break
                            j += 1   
                        # print (first, allele_list)
                    ##########for the case that ref is short than alt.#########             
                    if allele_list == first[2]:
                        reads_list[0].append(read.query_name)
                    elif allele_list == first[3]:
                        reads_list[1].append(read.query_name)
        for i in range(2):
            geno = i
            # if first[2] !=  first[4]:
            #     geno += 1
            for read_name in reads_list[i]:
                if read_name not in self.read_cover_geno:
                    self.read_cover_geno[read_name] = {}
                self.read_cover_geno[read_name][snp_index] = geno
    
    def get_discard_reads(self):
        if gene == "HLA_DRB1":
            for read in self.samfile.fetch("HLA_DRB1", 3898, 4400 ): #3898, 4400  3955, 4251
                self.discard_reads[read.query_name] = 1

    def for_each_locus(self):
        f = open(outdir + '/fragment.read.file', 'w')
        for snp in self.snp_list:
            pos = snp[1]
            snp_index = self.snp_index_dict[pos]
            self.get_sup_reads(snp, snp_index)
        for read_name in self.read_cover_geno:
            # print (self.read_cover_geno[read_name])
            record, support_loci_num = self.for_each_read(read_name)
            if support_loci_num > 1 and args.weight_imb != 1:
                print (record, file = f)
        f.close()

    def for_each_read(self, read_name):
        genotype = ''
        previous_locus = -100
        seg_num = 0
        for locus in self.read_cover_geno[read_name]:
            geno = self.read_cover_geno[read_name][locus]
            if locus - previous_locus != 1:
                genotype += ' ' + str(locus) + ' '
                genotype += str(geno) 
                seg_num += 1
            else:
                genotype += str(geno)     
            previous_locus = locus 
        support_loci_num = len(self.read_cover_geno[read_name])
        signal = "?"*support_loci_num
        if new_formate:
            record = f"{str(seg_num)} {read_name} 1 -1 -1 {genotype} {signal} {self.read_quality_dict[read_name]}"
        else:
            record = f"{str(seg_num)} {read_name}{genotype} {signal} {self.read_quality_dict[read_name]}"
        # print (genotype, seg_num)       
        # print (record)   
        return record, support_loci_num

def isin(x,seq):
    try:
        seq.index(x)
        return True
    except :
        return False

def read_block_hap():
    """
    read the phased block haplotypes
    """
    file=outdir+'/%s_break_points_phased.txt'%(gene)
    record_block_haps = []
    if os.path.isfile(file) and os.path.getsize(file):
        for line in open(file,'r'):
            if line[0] == '#':
                continue
            line=line.strip()
            array=line.split()
            gene_name=array[0]
            if gene_name != gene:
                print ("wrong gene!", gene_name, gene)
            start = int(array[1])
            end = int(array[2])
            genotype = int(array[3])
            record_block_haps.append([start, end, genotype])
    return record_block_haps

def block_phase(outdir,seq_list,snp_list,gene,gene_vcf,rephase_vcf,record_block_haps):
    """
    according to the block phase results
    refine the phased haplotypes
    output rephase_vcf
    return the haps
    """
    

    seq=np.array(seq_list)
    seq=np.transpose(seq)
    snp=snp_list  
    update_seqlist=[]

    he=0
    m = VariantFile(gene_vcf)
    
    if os.path.isfile(rephase_vcf):
        os.system('rm %s'%(rephase_vcf))
    out = VariantFile(rephase_vcf,'w',header=m.header)
    sample = list(m.header.samples)[0]
    for record in m.fetch():
        geno = record.samples[sample]['GT']    
        depth = record.samples[sample]['AD']
        if geno != (0,0) and geno != (1,1) and geno != (2,2):
            if geno == (1,2) or geno == (2,1):
                phased_locus = seq[he]
                for i in range(len(phased_locus)):
                    phased_locus[i] += 1
            else:
                phased_locus=seq[he]

            # check if it needs to reverse the genotype of the locus
            ref_order = [0, 1]
            for block in record_block_haps:
                if record.pos >= block[0] and record.pos <= block[1]:
                    if block[2] == 1:
                        ref_order = [1, 0]
                    break
            update_phased_locus=[]
            for pp in range(2):
                update_phased_locus.append(phased_locus[int(ref_order[pp])])
            phased_locus=update_phased_locus[:]
            # print (record, phased_locus)
            record.samples[sample]['GT']= tuple(phased_locus)
            record.samples[sample].phased=True

            if phased_locus[0] > 1 or phased_locus[1]>1:
                phased_locus[0]-=1
                phased_locus[1]-=1
            update_seqlist.append(phased_locus)
            he+=1
        out.write(record)
    m.close()
    out.close()
    os.system('tabix -f %s'%(rephase_vcf))
    return update_seqlist

def gene_phased(update_seqlist,snp_list, gene):
    gene_profile={}
    gene_snp=[]
    gene_seq=[]
    for i in range(len(snp_list)):
        if snp_list[i][0] == gene:
            gene_snp.append(snp_list[i])
            gene_seq.append(update_seqlist[i])
    gene_seq = np.array(gene_seq) 
    gene_seq = np.transpose(gene_seq)
    gene_profile[gene] = [gene_snp,gene_seq]
    return gene_profile

def no_snv_gene_phased(outdir, gene):
    """
    The haplotype frequency is [1, 0], if there is no hete variant
    output the frequency file
    return an empty gene_profile
    """

    fresh_alpha = [1, 0]
    hete_var_num = 0 # num of hete variants is zero
    freq_output(outdir, gene, fresh_alpha, hete_var_num)

    gene_profile={}
    gene_snp=[]
    gene_seq=[]
    gene_profile[gene] = [gene_snp,gene_seq]

    return gene_profile

def focus_region():
    # return the gene interval on the reference
    return {'HLA_A':[1000,4503],'HLA_B':[1000,5081],'HLA_C':[1000,5304],'HLA_DPA1':[1000,10775],\
        'HLA_DPB1':[1000,12468],'HLA_DQA1':[1000,7492],'HLA_DQB1':[1000,8480],'HLA_DRB1':[1000,12229]}

class Share_reads():

    def __init__(self, deletion_region, outdir, strainsNum, gene, gene_profile, ins_seq):
        self.deletion_region = deletion_region
        # print ('initial', self.deletion_region)
        self.bamfile = outdir + '/newref_insertion.bam'
        self.vcf = outdir + '/%s.insertion.phased.vcf.gz'%(gene)
        self.strainsNum = strainsNum
        self.gene = gene
        self.normal_sequence=gene_profile[self.gene]
        self.before_dup_reads = [[], []] # record reads before the 3988 for DRB1, for finding dup type, not using
        self.reads_support = self.normal_reads()
        self.outdir = outdir
        self.ins_seq = ins_seq
        self.dup_file = outdir +'/select.DRB1.seq.txt'
        
    def generate_normal_region(self):
        gene_area = focus_region()[self.gene]
        normal_region = []
        segs = []
        gene_area[0] = int(float(gene_area[0])) + 1
        gene_area[1] = int(float(gene_area[1]))
        start = gene_area[0]
        # print (self.deletion_region)
        for i in range(len(self.deletion_region)):
            if self.deletion_region[i][1] > gene_area[1]:
                self.deletion_region[i][1] = gene_area[1]
            if start < self.deletion_region[i][0]:
                segs.append([start, self.deletion_region[i][0] - 1, 'normal', '.'])
            if self.deletion_region[i][0] == self.deletion_region[i][1]:
                segs.append([self.deletion_region[i][0], self.deletion_region[i][1], 'insertion', i])
                # continue
            else:
                segs.append([self.deletion_region[i][0], self.deletion_region[i][1], 'deletion', i])
            normal_region.append([start, self.deletion_region[i][0]])
            start = self.deletion_region[i][1] + 1
        if int(start) < gene_area[1]:
            normal_region.append([start, gene_area[1]])
            segs.append([start, gene_area[1], 'normal', '.'])
        return normal_region, segs

    def normal_reads(self):
        normal_region, segs = self.generate_normal_region()
        # print ("normal region", normal_region)
        reads_support = [[], []]
        samfile = pysam.AlignmentFile(self.bamfile, "rb")
        for region in normal_region:
            if abs(region[0] - region[1]) < 10:
                continue
            for read in samfile.fetch(self.gene, region[0] - 1, region[1]):
                rivet_points=False
                support_alleles=[]
                support_loci=[]
                for i in range(len(self.normal_sequence[0])):
                    snv=self.normal_sequence[0][i]
                    if len(snv[2]) != 1 or len(snv[3]) != 1:
                        continue
                    if int(snv[1])-1 in read.get_reference_positions(full_length=True):
                        reads_index=read.get_reference_positions(full_length=True).index(int(snv[1])-1)
                        support_alleles.append(read.query_sequence[reads_index])
                        # print (read.query_name,snv,support_alleles)
                        rivet_points=True
                        support_loci.append(i)
                if rivet_points==True:
                    #if the reads has information, check which hap it belongs to.
                    hap_belong=self.check_hap(support_alleles,support_loci)[0]
                    if hap_belong != 'NA':
                        reads_support[hap_belong].append(read.query_name)
                        if self.gene == "HLA_DRB1" and read.reference_start < 3988: 
                            self.before_dup_reads[hap_belong].append(read.query_name)

        # print (len(reads_support[0]), len(self.before_dup_reads[0]))
        return reads_support

    def check_hap(self,support_alleles,support_loci):
        support_num=[]  #check the allele num that support the each hap respectively.
        for i in range(self.strainsNum):
            support_num.append(0)
        for i in range(len(support_loci)):
            locus_index=support_loci[i]
            allele=support_alleles[i]
            snv=self.normal_sequence[0][locus_index]
            for j in range(self.strainsNum):
                hap_allele=snv[self.normal_sequence[1][j][locus_index]+2]
                if hap_allele == allele:
                    support_num[j] += 1
        #check which hap has most same alleles support_num.index(max(support_num))
        return self.most_support(support_num)

    def most_support(self,support_num):
        hap_order = np.argsort(np.array(support_num))[::-1]
        return hap_order

    def deletion_reads(self,deletion_index):
        link_reads=[]  #the reads number that shared with different haps, the copy number may be 0
        for i in range(self.strainsNum):
            link_reads.append(0)
        samfile = pysam.AlignmentFile(self.bamfile, "rb")
        for read in samfile.fetch(self.gene,float(self.deletion_region[deletion_index][0])-1,float(self.deletion_region[deletion_index][1])):
            #print (deletion_index, read.query_name, float(self.deletion_region[deletion_index][0])-1, float(self.deletion_region[deletion_index][1]))
            for i in range(self.strainsNum):
                if read.query_name in self.reads_support[i]:
                    link_reads[i] += 1
        print ("deletion index is", deletion_index, link_reads, self.most_support(link_reads))   
        return self.most_support(link_reads)

    def insertion_reads(self,deletion_index):
        link_reads=[]  #the reads number that shared with different haps, the copy number may be 0
        for i in range(self.strainsNum):
            link_reads.append(0)
        samfile = pysam.AlignmentFile(self.bamfile, "rb")
        map_ins_read_num = 0
        ins_segment_name = '%s_%s'%(self.gene,self.deletion_region[deletion_index][0])
        for read in samfile.fetch(ins_segment_name):
            for i in range(self.strainsNum):
                if read.query_name in self.reads_support[i]:
                    link_reads[i] += 1
            map_ins_read_num += 1
        print ("insertion index is", deletion_index, link_reads, self.most_support(link_reads), "read num is", map_ins_read_num, "ins name", ins_segment_name)  
        return self.most_support(link_reads)

    def deletion_phase(self):
        for deletion_index in range(len(self.deletion_region)):
            # print (self.deletion_region[deletion_index])
            self.deletion_reads(deletion_index)

    def dup_assign(self):       
        #uniq reads for each dup type
        drb1_complex_seq, uniq_drb1_complex_reads = DRB1_complex_region(self.dup_file)
        #the relation between dup type and snv-haplotype
        new_drb1_complex_seq = []
        for i in range(self.strainsNum):
            max_num = 0
            max_seq = ''
            for j in range(len(drb1_complex_seq)):
                num = 0
                for re in uniq_drb1_complex_reads[j]:
                    # if re in self.reads_support[i]:
                    if re in self.before_dup_reads[i]:
                        num+=1
                if num >= max_num:
                    max_num = num
                    max_seq = drb1_complex_seq[j]
                print ('DRB1 assign dup seq', i, j, num, len(drb1_complex_seq))
            new_drb1_complex_seq.append(max_seq)
        return new_drb1_complex_seq

    def split_seg(self):
        # print ('start split seg.')
        if self.gene == 'HLA_DRB1':
            my_drb1_complex_seq = self.dup_assign()
        normal_region, segs = self.generate_normal_region()
        id_name = {}
        gap = ''
        contain_dup_seg = ''
        for seg in segs:
            print ('seg', seg)
            if seg[2] == 'insertion':
                continue
            if self.gene == 'HLA_DRB1' and seg[0] < 3898 and seg[1] > 4400:
                contain_dup_seg = seg
                seg[2] = 'dup'
                seg_region = ' %s:%s-3898 %s:3898-4400 %s:4400-%s '%(self.gene,\
                seg[0],self.gene,self.gene,seg[1])
                seg_region_front = ' %s:%s-3898 '%(self.gene, seg[0])
                seg_region_dup = ' %s:3898-4400 '%(self.gene)
                seg_region_behind = ' %s:4400-%s '%(self.gene,seg[1])
                id_name[seg_region_front.strip()] = str(seg[0])+'>'
                id_name[seg_region_dup.strip()] = str(seg[0])+'='
                id_name[seg_region_behind.strip()] = str(seg[1])+'<'
            else:
                seg_region = ' %s:%s-%s '%(self.gene,seg[0],seg[1])
                id_name[seg_region.strip()] = str(seg[0]) + '_' + str(seg[1]) 
            gap += seg_region
        for i in range(self.strainsNum):
            order='%s/../bin/samtools faidx %s/../db/ref/hla.ref.extend.fa\
                %s |%s/../bin/bcftools consensus --mask %s -H %s %s/%s.rephase.vcf.gz\
                      >%s/%s_%s_seg.fa'%(sys.path[0],sys.path[0],gap,sys.path[0],mask_bed,i+1,self.outdir,\
                self.gene,self.outdir,self.gene,i)
            os.system(order)
            fa_file = '%s/%s_%s_seg.fa'%(self.outdir,self.gene,i)
            seg_sequence = chrom_seq(fa_file)
            new_seg_sequence = {}
            for segseq in seg_sequence.keys():
                new_seg_sequence[id_name[segseq]] = seg_sequence[segseq]
            hap_seq = ''
            for seg in segs:
                if seg[2] == 'normal':
                    hap_seq += new_seg_sequence[str(seg[0]) + '_' + str(seg[1]) ]
                elif seg[2] == 'deletion':
                    deletion_index = seg[3]
                    assign_index = self.deletion_reads(deletion_index)[0]
                    print ('deletion assign index', assign_index, "copy number is", \
                        self.deletion_region[deletion_index][2], self.deletion_region[deletion_index])
                    if  i == assign_index and self.deletion_region[deletion_index][2] == 1:
                        hap_seq += new_seg_sequence[str(seg[0]) + '_' + str(seg[1]) ]
                elif seg[2] == 'insertion':
                    deletion_index = seg[3]
                    assign_index = self.insertion_reads(deletion_index)[0]
                    print ('insertion assign index', assign_index,"copy number is", self.deletion_region[deletion_index][2], seg)
                    insertion_seg = '%s_%s'%(self.gene, seg[0])
                    if self.deletion_region[deletion_index][2] == 2:                        
                        insert_seq = self.link_diploid_insertion(insertion_seg)
                        hap_seq += insert_seq[i]                      
                    elif  i == assign_index and self.deletion_region[deletion_index][2] == 1:
                        hap_seq += self.consensus_insertion(insertion_seg)
                    else:
                        print ("seems fasle positive INS, skip")

                elif seg[2] == 'dup':
                    # print ('the seg contain dup region')
                    # the seg that contain the dup region
                    hap_seq += new_seg_sequence[str(seg[0])+'>']
                    #add the seq of chosen dup type
                    hap_seq += my_drb1_complex_seq[i]
                    # the seg that contain the dup region
                    hap_seq += new_seg_sequence[str(seg[1])+'<']                    
            hap_seq =  '>%s_%s\n'%(self.gene, i) + hap_seq[:]
            out = open('%s/hla.allele.%s.%s.fasta'%(self.outdir,i+1,self.gene), 'w')
            print (hap_seq, file = out)
            out.close()

    def link_diploid_insertion(self, insertion_seg):
        # insertion_seg = 'HLA_DRB1_6355'
        insert_reads_support = []
        for i in range(self.strainsNum):
            insert_reads_support.append([])

        in_vcf = VariantFile(self.vcf)
        sample = list(in_vcf.header.samples)[0]
        insert_phase_result = [[],[]]
        for record in in_vcf.fetch():
            geno = record.samples[sample]['GT']    
            depth = record.samples[sample]['AD']
            if record.chrom !=  insertion_seg:
                continue
            if geno == (1, 1):
                continue
            if geno == (0, 1):
                insert_phase_result[0].append([record.pos, record.ref])
                insert_phase_result[1].append([record.pos, record.alts[0]])
            elif geno == (1, 0):
                insert_phase_result[1].append([record.pos, record.ref])
                insert_phase_result[0].append([record.pos, record.alts[0]])  
            if len(insert_phase_result[0]) > 0:
                if len(insert_phase_result[1][-1][1]) != 1 or  len(insert_phase_result[0][-1][1]) != 1:
                    continue          

        samfile = pysam.AlignmentFile(self.bamfile, "rb")
        for read in samfile.fetch(insertion_seg):
            rivet_points=False
            support_alleles=[]
            support_loci=[]
            for i in range(len(insert_phase_result[0])):
                snv1 =insert_phase_result[0][i]
                snv2 =insert_phase_result[1][i]
                if int(snv1[0])-1 in read.get_reference_positions(full_length=True):
                    reads_index=read.get_reference_positions(full_length=True).index(int(snv1[0])-1)
                    if read.query_sequence[reads_index] == snv1[1]:
                        insert_reads_support[0].append(read.query_name)
                    elif read.query_sequence[reads_index] == snv2[1]:
                        insert_reads_support[1].append(read.query_name)
        r00 = 0
        for i in range(2):
            for j in range(len(insert_reads_support[i])):
                if insert_reads_support[i][j] in self.reads_support[i]:
                    r00 += 1
        r01 = 0
        for i in range(2):
            for j in range(len(insert_reads_support[i])):
                if insert_reads_support[i][j] in self.reads_support[1-i]:
                    r01 += 1
        fastq_seq = []
        for i in range(2):
            order = """
            %s/../bin/samtools faidx %s/newref_insertion.fa %s|%s/../bin/bcftools consensus -H %s %s  >%s/seq_%s_%s.fa
            """%(sys.path[0], self.outdir, insertion_seg, sys.path[0], i+1, self.vcf, self.outdir, i, insertion_seg)
            os.system(order)
            fastq_seq.append(read_fasta('%s/seq_%s_%s.fa'%(self.outdir, i, insertion_seg)))
        print ('link long indel supporting reads', r00, r01)
        if  r01 > r00:
            return [fastq_seq[1], fastq_seq[0]]
        else:
            return fastq_seq  

    def consensus_insertion(self, insertion_seg):
        order = """
        %s/../bin/samtools faidx %s/newref_insertion.fa %s|%s/../bin/bcftools consensus -H %s %s  >%s/seq
        """%(sys.path[0], self.outdir, insertion_seg, sys.path[0], 1, self.vcf, self.outdir)
        os.system(order)
        cons_seq = read_fasta('%s/seq'%(self.outdir))
        return cons_seq

def chrom_seq(file):
    f = open(file, 'r')
    seg_sequence = {}
    name = 'start'
    seq = ''
    for line in f:
        line = line.strip()
        if line[0] == '>':
            seg_sequence[name] = seq
            name = line[1:]
            seq = ''
        else:
            seq += line
    seg_sequence[name] = seq
    del seg_sequence['start']
    return seg_sequence

def read_fasta(file):
    # return the sequence saved in fasta file
    seq=''
    for line in open(file, 'r'):
        if line[0] == '>':
            continue
        line=line.strip()
        seq+=line
    return seq
        
def segment_mapping_pre(fq1, fq2, ins_seq, outdir, gene, gene_ref):
    newref=outdir+'/newref_insertion.fa'
    os.system('cp %s %s'%(gene_ref, newref))
    for seg in ins_seq.keys():

        f = open(newref, 'a')
        print ('>%s_%s\n%s'%(gene, int(seg), ins_seq[seg]), file = f)
        f.close()
        # index the ref
    print ('New mapping starts to link long InDels.')
    map_call = """\
        bindir=%s/../bin/
        outdir=%s/ 
        sample='newref_insertion' 
        $bindir/samtools faidx %s 
        $bindir/bwa index %s
        group='@RG\\tID:sample\\tSM:sample'  #only -B 1
        $bindir/bwa mem -t %s -B 1 -O 1,1 -L 1,1 -U 1 -R $group -Y %s %s %s | $bindir/samtools view -q 1 -F 4 -Sb | $bindir/samtools sort > $outdir/$sample.sort.bam
        java -jar  $bindir/picard.jar MarkDuplicates INPUT=$outdir/$sample.sort.bam OUTPUT=$outdir/$sample.bam METRICS_FILE=$outdir/metrics.txt
        rm -rf $outdir/$sample.sort.bam 
        $bindir/samtools index $outdir/$sample.bam 
        $bindir/freebayes -f %s -p 2 $outdir/$sample.bam > $outdir/$sample.freebayes.1.vcf 
        cat $outdir/$sample.freebayes.1.vcf| sed -e 's/\//\|/g'>$outdir/$sample.freebayes.vcf 
        bgzip -f $outdir/$sample.freebayes.vcf 
        tabix -f $outdir/$sample.freebayes.vcf.gz
        """%(sys.path[0], outdir, newref, newref, args.thread_num, newref, fq1, fq2, newref)
    os.system(map_call)
    # print (ins_seq)
    for ins in ins_seq.keys():
        ins_call = """%s/../bin/samtools faidx %s/newref_insertion.fa %s_%s |%s/../bin/bcftools consensus -H 1 %s/newref_insertion.freebayes.vcf.gz  >%s/fresh_ins.fa
        """%(sys.path[0],outdir,gene,int(ins),sys.path[0],outdir,outdir)
        # print ('#####################', ins, ins_call)
        os.system(ins_call)
        ins_seq[ins] = read_fasta('%s/fresh_ins.fa'%(outdir))
    # print (ins_seq)
    return ins_seq
    
def segment_mapping(fq1, fq2, ins_seq, outdir, gene, gene_ref):
    newref=outdir+'/newref_insertion.fa'
    os.system('cp %s %s'%(gene_ref, newref))
    for seg in ins_seq.keys():

        f = open(newref, 'a')
        print ('>%s_%s\n%s'%(gene, int(seg), ins_seq[seg]), file = f)
        f.close()
        # index the ref
    print ('New mapping starts to link long InDels.')
    map_call = """\
        bindir=%s/../bin/
        outdir=%s/ 
        sample='newref_insertion' 
        $bindir/samtools faidx %s 
        $bindir/bwa index %s
        group='@RG\\tID:sample\\tSM:sample'  #only -B 1
        $bindir/bwa mem -t %s -B 1 -O 1,1 -L 1,1 -U 1 -R $group -Y %s %s %s | $bindir/samtools view -q 1 -F 4 -Sb | $bindir/samtools sort > $outdir/$sample.sort.bam
        java -jar  $bindir/picard.jar MarkDuplicates INPUT=$outdir/$sample.sort.bam OUTPUT=$outdir/$sample.bam METRICS_FILE=$outdir/metrics.txt
        rm -rf $outdir/$sample.sort.bam 
        $bindir/samtools index $outdir/$sample.bam 
        $bindir/freebayes -f %s -p 2 $outdir/$sample.bam > $outdir/$sample.freebayes.vcf 
        """%(sys.path[0], outdir, newref, newref, args.thread_num, newref, fq1, fq2, newref)
    os.system(map_call)

def get_insertion_linkage(ins_seq):
    """
    To get the linkage information for long insertions
    The long insertion sequence and the reference are combined to generate a modified reference
    Map the reads to the modified reference
    """
    if len(ins_seq) > 0:
        ins_seq = segment_mapping_pre(fq1, fq2, ins_seq, outdir, gene, hla_ref)
        segment_mapping(fq1, fq2, ins_seq, outdir, gene, hla_ref)
    else:
        # os.system('cp %s/%s.bam %s/newref_insertion.bam'%(outdir, gene.split('_')[-1], outdir))
        os.system('cp %s %s/newref_insertion.bam'%(bamfile, outdir))
        os.system('%s/../bin/samtools index %s/newref_insertion.bam'%(sys.path[0], outdir))
        os.system('zcat %s > %s/newref_insertion.freebayes.vcf'%(gene_vcf, outdir))
    return ins_seq

def get_copy_number(outdir, deletion_region, gene, ins_seq):
    os.system('%s/../bin/samtools depth -aa %s/newref_insertion.bam >%s/newref_insertion.depth'%(sys.path[0],outdir, outdir))
    normal_depth = []
    deletions_depth_list = []
    for i in range(len(deletion_region)):
        deletions_depth_list.append([])

    for line in open('%s/newref_insertion.depth'%(outdir)):
        array = line.strip().split()
        if array[0] != gene:
            continue
        deletion_flag = False
        for i in range(len(deletion_region)):
            if float(array[1]) >= float(deletion_region[i][0]) and float(array[1]) < float(deletion_region[i][1]):
                deletions_depth_list[i].append(float(array[2]))
                deletion_flag = True
        if deletion_flag == False:
            normal_depth.append(float(array[2]))

    insertions_depth_list = {}
    for seg in ins_seq.keys():
        chrom_name = '%s_%s'%(gene, int(seg))
        insertions_depth_list[chrom_name] = []
    # print (insertions_depth_list.keys())
    
    for line in open('%s/newref_insertion.depth'%(outdir)):
        array = line.strip().split()
        if array[0] in insertions_depth_list.keys():
            insertions_depth_list[array[0]].append(float(array[2]))


    remove_indel_index = []
    for i in range(len(deletion_region)):
        # deletion_region[i] += [np.mean(deletions_depth_list[i])/np.mean(normal_depth), zero_per(deletions_depth_list[i])]
        if float(deletion_region[i][0]) == float(deletion_region[i][1]):
            seg_type = "INS"
            chrom_name = '%s_%s'%(gene, int(deletion_region[i][0]))
            # print ('compute assign index', np.mean(insertions_depth_list[chrom_name]),np.mean(normal_depth))
            if len(insertions_depth_list[chrom_name]) == 0:
                ratio = 0
            else:
                ratio = np.mean(insertions_depth_list[chrom_name])/np.mean(normal_depth)
            if ratio > 0.85:
                deletion_region[i] += [2]
            elif ratio > 0.1 and ratio <= 0.85:
                deletion_region[i] += [1]
            else:
                deletion_region[i] += [0]
                remove_indel_index.append(i)
            print ('### copy number', seg_type, ratio)
        else:
            seg_type = "DEL"
            # print ('compute copy number for deletion', deletion_region[i], zero_per(deletions_depth_list[i]))
            zero_rate = zero_per(deletions_depth_list[i])
            if  zero_rate> 0.2:
                deletion_region[i] += [0]
            else:
                deletion_region[i] += [1]
            print ('### copy number', seg_type, deletion_region[i], zero_rate)
    for i in remove_indel_index:
        print ("discard", deletion_region[i])
        del deletion_region[i]
    deletion_region = sort_intervals(deletion_region)
    return deletion_region

def zero_per(list):
    zero_num = 0
    for li in list:
        if li < 3:
            zero_num  += 1
    return zero_num/len(list)

def uniq_reads(raw_reads_set):
    dup_type_Num = len(raw_reads_set)
    uniq_reads_set = []
    for i in range(dup_type_Num):
        uniq_set = []
        for ele in raw_reads_set[i]:
            uniq_flag = True
            for j in range(dup_type_Num):
                if i == j:
                    continue
                if ele in raw_reads_set[j]:
                    uniq_flag = False
            if uniq_flag == True:
                uniq_set.append(ele)
        uniq_reads_set.append(uniq_set)
    # print ('uniq reads', len(uniq_reads_set[0]), len(uniq_reads_set[1]))
    return uniq_reads_set

def DRB1_complex_region(drb1_complex_file):
    drb1_complex_seq = []
    drb1_complex_reads = []
    for line in open(drb1_complex_file, 'r'):
        line = line.strip()
        array = line.split()
        drb1_complex_seq.append(array[5])
        reads_list = []
        raw_reads_list = array[6].split(';')
        for reads in raw_reads_list[:-1]:
            reads_list.append(reads[:-3])
        drb1_complex_reads.append(reads_list)
    # print ('There are %s dup types.'%(len(drb1_complex_seq)))
    uniq_drb1_complex_reads = uniq_reads(drb1_complex_reads)
    return drb1_complex_seq, uniq_drb1_complex_reads

def sv2fasta(ref, seg_order, index_locus, ins_seq, outdir):
    ref_seq = read_fasta(ref)
    normal_dict = {}
    for seg in index_locus.keys():
        if seg in ins_seq.keys():
            continue
        normal_dict[seg] = ref_seq[index_locus[seg][0]-1 : index_locus[seg][1]-1]
    for i in range(len(seg_order)):
        seg_array = seg_order[i].strip().split()
        hap_seq = '>sv_hap_%s\n'%(i)
        out = open(outdir + '/sv_hap_%s.fa'%(i), 'w')
        for arr in seg_array:
            seg_name = arr[:-1]
            if seg_name in ins_seq.keys():
                my_seq = ins_seq[seg_name]
            else:
                my_seq = normal_dict[seg_name]
            hap_seq += my_seq
        print (hap_seq, file = out)
        out.close()

def dup_region_type(outdir, strainsNum, bamfile):
    order = r"""
        bam=%s
        outdir=%s
        k=%s
        pos=HLA_DRB1:3898-4400        
        ref=%s/../db/ref/DRB1_dup_extract_ref.fasta
        %s/../bin/samtools view -f 64 $bam $pos| cut -f 1,6,10|sort|uniq |awk '{OFS="\n"}{print ">"$1"##1 "$2,$3}' > $outdir/extract.fa
        %s/../bin/samtools view -f 128 $bam $pos| cut -f 1,6,10|sort|uniq |awk '{OFS="\n"}{print ">"$1"##2 "$2,$3}' >> $outdir/extract.fa
        %s/../bin/blastn -query $outdir/extract.fa -out $outdir/extract.read.blast -db $ref -outfmt 6 -strand plus  -penalty -1 -reward 1 -gapopen 4 -gapextend 1
        perl %s/count.read.pl $outdir
        less $outdir/DRB1.hla.count| sort -k3,3nr -k4,4nr | head -n $k |awk '$3>0.7'|awk '$4>5' >$outdir/select.DRB1.seq.txt
        """%(bamfile, outdir, strainsNum, sys.path[0], sys.path[0], sys.path[0],sys.path[0], sys.path[0])
    os.system(order)

def long_InDel_breakpoints(bfile):
    sv_dict = {}
    if not os.path.isfile(bfile):
        return sv_dict
    f = open(bfile, 'r')
    for line in f:
        line = line.strip()
        array = line.split()
        if array[0] != array[3]:
            continue
        if array[0] == 'HLA_DRB1':
            if int(array[1]) > 3800 and int(array[1]) < 4500:
                continue
            if int(array[4]) > 3800 and int(array[4]) < 4500:
                continue
        sv = [array[1], array[4], array[6]]
        #sv = [array[1], array[4], array[6], int(array[7])]
        if array[0] not in sv_dict:
            sv_dict[array[0]] = [sv]
        else:
            sv_dict[array[0]].append(sv)
    return sv_dict

def get_deletion_region(long_indel_file, gene):
    sv_dict = long_InDel_breakpoints(long_indel_file) # record the long indel
    if gene in sv_dict.keys():
        sv_list = sv_dict[gene]
    else:
        sv_list = []
    # print (sv_list)
    deletion_region = []
    ins_seq = {}
    insertion = []
    points = []
    new_deletion_region = []
    for sv in sv_list:
        if sv[0] != sv[1]:
            points.append(int(float(sv[0])))
            points.append(int(float(sv[1])))
            deletion_region.append([int(float(sv[0])), int(float(sv[1]))])
            # deletion_region.append([int(float(sv[0])), int(float(sv[1])), int(sv[3])])
        else:
            #remove redundant insertions
            uniq_ins = True
            for region in new_deletion_region:
                if region[0] != region[1]:
                    continue
                if abs(int(sv[0]) - region[0]) < 50:
                    uniq_ins = False
            if uniq_ins:
                # new_deletion_region.append([int(float(sv[0])), int(float(sv[1])), int(sv[3])])
                new_deletion_region.append([int(float(sv[0])), int(float(sv[1]))])
                seg = float(sv[0])
                ins_seq[seg] = sv[2]                

    start = 1
    split_segs = []
    for p in sorted(points):
        if start == p:
            continue
        split_segs.append([start, p])
        start = p
  
    for segs in split_segs:
        delete_flag = False
        for re in deletion_region:
            if segs[0] >= re[0] and segs[1] <= re[1]:
                delete_flag = True
        if delete_flag and segs[1] - segs[0] > 4:
            new_deletion_region.append(segs)
    deletion_region = new_deletion_region
    # print ('new_deletion_region',deletion_region)
    deletion_region = sort_intervals(deletion_region)
    # print ('#ordered deletion region:', deletion_region)
    return deletion_region, ins_seq

def sort_intervals(deletion_region):
    while True:
        flag = True
        new_deletion_region = deletion_region[:]
        # print (new_deletion_region)
        for i in range(len(deletion_region) - 1):
            if deletion_region[i+1][0] < deletion_region[i][0]:
                flag = False
                new_deletion_region[i] = deletion_region[i+1]
                new_deletion_region[i+1] = deletion_region[i]
                # print ('ite', i, new_deletion_region)
                break
            elif deletion_region[i][1] > deletion_region[i+1][1]:
                new_deletion_region[i] = [deletion_region[i][0], deletion_region[i+1][0]]
                new_deletion_region[i+1] = [deletion_region[i+1][0], deletion_region[i+1][1]]
                new_deletion_region.append([deletion_region[i+1][1], deletion_region[i][1]])
                break
        deletion_region = new_deletion_region[:]
        # print (deletion_region)
        if flag:
            break
    return deletion_region

def get_unphased_loci(outdir, gene, invcf, snp_list, spec_vcf):
    """
    Input: the phased vcf of SpecHap
    Return: the loci used to break phase blocks, and refined vcf file
    The blocks will be phased by the allele database
    """  
    bp = open(outdir + '/%s_break_points_spechap.txt'%(gene), 'w')
    print ('#gene   locus   break_pos', file = bp)
    m = VariantFile(invcf)
    out = VariantFile(spec_vcf,'w',header=m.header)
    sample = list(m.header.samples)[0]
    add_block = 1
    i = 0
    block_boundaries = []
    used_locus = []
    single_point_in_dup = 0
    for record in m.fetch():
        if record.chrom != gene:
            continue
        if record.samples[sample]['GT'] == (1,1) or record.samples[sample]['GT'] == (0,0) or record.samples[sample]['GT'] == (2,2):
            record.samples[sample].phased = True
            out.write(record)
            continue

        if record.samples[sample].phased != True:
            record.samples[sample]['PS'] = add_block
            if record.samples[sample]['GT'] != (1,1) and record.samples[sample]['GT'] != (0,0) and record.samples[sample]['GT'] != (2,2):
                # some loci might not be phased.
                # break at the unphased locus
                if i > 0 and past_record.pos not in used_locus:
                    used_locus.append(past_record.pos)

                    max_allele_length = len(past_record.ref)
                    for alt in past_record.alts:
                        if len(alt) > max_allele_length:
                            max_allele_length = len(alt)
                    if record.chrom == "HLA_DRB1" and past_record.pos >= 3880 and  past_record.pos <= 4400:
                        single_point_in_dup += 1
                        if single_point_in_dup == 1:
                            print (past_record.chrom, past_record.pos, past_record.pos+max_allele_length, file = bp)
                            block_boundaries.append(past_record.pos+max_allele_length)
                    else:
                        print (past_record.chrom, past_record.pos, past_record.pos+max_allele_length, file = bp)
                        block_boundaries.append(past_record.pos+max_allele_length)
            record.samples[sample].phased = True

        if record.samples[sample]['PS'] != add_block:
            # this variant is located on a new block
            # break from the last variant
            if i > 0 and past_record.pos not in used_locus:
                used_locus.append(past_record.pos)

                max_allele_length = len(past_record.ref)
                for alt in past_record.alts:
                    if len(alt) > max_allele_length:
                        max_allele_length = len(alt)

                if record.chrom == "HLA_DRB1" and past_record.pos >= 3880 and  past_record.pos <= 4400:
                    single_point_in_dup += 1
                    if single_point_in_dup == 1:
                        print (past_record.chrom, past_record.pos, past_record.pos+max_allele_length, file = bp)
                        block_boundaries.append(past_record.pos+max_allele_length)
                else:
                    print (past_record.chrom, past_record.pos, past_record.pos+max_allele_length, file = bp)
                    block_boundaries.append(past_record.pos+max_allele_length)

            # print (past_record.pos, add_block, record.samples[sample]['PS'])
            add_block = record.samples[sample]['PS']

        if record.samples[sample]['GT'] != (1,1) and record.samples[sample]['GT'] != (0,0)  and record.samples[sample]['GT'] != (2,2):
            i += 1
            past_record = record
        # print (record.pos, break_points)
        out.write(record)
    m.close()
    out.close()
    bp.close()
    os.system('tabix -f %s'%(spec_vcf))
    print ("%s blocks after phasing."%(len(block_boundaries)+1))
    return block_boundaries

def phase_insertion(gene, outdir, hla_ref, shdir):
    order = """
    sample=%s
    outdir=%s
    ref=%s
    cat $outdir/newref_insertion.freebayes.vcf|grep '#'>$outdir/filter_newref_insertion.freebayes.vcf
    awk -F'\t' '{if($6>5) print $0}' $outdir/newref_insertion.freebayes.vcf|grep -v '#' >>$outdir/filter_newref_insertion.freebayes.vcf
    %s/../bin/ExtractHAIRs --triallelic 1 --mbq 4 --mmq 0 --indels 1 \
    --ref $ref --bam $outdir/newref_insertion.bam --VCF $outdir/filter_newref_insertion.freebayes.vcf --out $outdir/$sample.fragment.file > spec.log 2>&1
    sort -n -k3 $outdir/$sample.fragment.file >$outdir/$sample.fragment.sorted.file
    bgzip -f $outdir/filter_newref_insertion.freebayes.vcf
    tabix -f $outdir/filter_newref_insertion.freebayes.vcf.gz
    %s/../bin/SpecHap/build/SpecHap --ncs --window_size 15000 -N --vcf $outdir/filter_newref_insertion.freebayes.vcf.gz --frag $outdir/$sample.fragment.sorted.file --out $outdir/$sample.insertion.phased.raw.vcf
    cat $outdir/$sample.insertion.phased.raw.vcf| sed -e 's/1\/1/1\|1/g'>$outdir/$sample.insertion.phased.vcf
    bgzip -f $outdir/$sample.insertion.phased.vcf
    tabix -f $outdir/$sample.insertion.phased.vcf.gz
    """%(gene, outdir, hla_ref, sys.path[0], shdir)
    os.system(order)
    print ('insertion phasing done.')

def compute_allele_frequency(geno_set,beta_set):
    # compute allele frequency with least square
    locus_num = 0
    alpha = np.array([0.0, 0.0])
    for i in range(len(beta_set)):
        beta = beta_set[i][1]
        if geno_set[i][0] == 0:
            alpha[0] += (1-beta)
            alpha[1] += beta
            locus_num += 1
        elif geno_set[i][0] == 1:
            alpha[0] += beta
            alpha[1] += (1-beta)
            locus_num += 1
    if locus_num > 0:
        freqs = alpha/locus_num
        return [round(freqs[0], 3), round(freqs[1], 3)]
    else:
        return [1, 0]

def allele_imba_old(beta_set):
    """
    Utilizing allelic imbalance information to phase
    get the linkage info from allele frequencies at each variant locus
    return the linkage info with a SpecHap acceptable format
    """
    
    f = open(outdir + '/fragment.imbalance.file', 'w')
    base_q = round(60 * float(args.weight_imb))
    if base_q >= 1:
        locus_num = len(beta_set)
        for i in range(locus_num - 1):
            j = i + 1
            first_locus = snp_index_dict[snp_list[i][1]]
            second_locus = snp_index_dict[snp_list[j][1]]
            same = max([ beta_set[i][0] *  beta_set[j][0], beta_set[i][1] *  beta_set[j][1] ])
            reverse = max([ beta_set[i][0] *  beta_set[j][1], beta_set[i][1] *  beta_set[j][0] ])
            linkage_name = "linkage_inferred_by_allele_imbalance:%s:%s"%(first_locus, second_locus)
            if new_formate:
                if same > reverse:
                    print('2 %s:1 1 -1 -1 %s %s %s %s ?? %s'%(linkage_name, first_locus, 0, second_locus, 0, int(base_q*same)), file=f)
                else:
                    print('2 %s:2 1 -1 -1 %s %s %s %s ?? %s'%(linkage_name, first_locus, 0, second_locus, 1, int(base_q*reverse)), file=f)
            else:
                if same > reverse:
                    print('2 %s:1 %s %s %s %s ?? %s'%(linkage_name, first_locus, 0, second_locus, 0, int(base_q*same)), file=f)
                else:
                    print('2 %s:2 %s %s %s %s ?? %s'%(linkage_name, first_locus, 0, second_locus, 1, int(base_q*reverse)), file=f)

    f.close()

def allele_imba(beta_set):
    """
    Utilizing allelic imbalance information to phase
    get the linkage info from allele frequencies at each variant locus
    return the linkage matrix with a SpecHap acceptable format
    """
    f = open(outdir + '/fragment.imbalance.file', 'w')
    locus_num = len(beta_set)
    for i in range(locus_num - 1):
        j = i + 1
        same = max([ beta_set[i][0] *  beta_set[j][0], beta_set[i][1] *  beta_set[j][1] ])
        reverse = max([ beta_set[i][0] *  beta_set[j][1], beta_set[i][1] *  beta_set[j][0] ])

        edge_same = max(np.log(same/reverse), 0)
        edge_reverse = max(np.log(reverse/same), 0)
        first_locus = snp_index_dict[snp_list[i][1]] - 1 # 0 index
        second_locus = snp_index_dict[snp_list[j][1]] - 1
        print (second_locus, first_locus, edge_same, edge_reverse, edge_reverse, edge_same, file = f)
    f.close()

def run_SpecHap():
    mmp = MNP_linkage(bamfile,snp_list,snp_index_dict,outdir)
    mmp.for_each_locus() 

    allele_imba(beta_set) # linkage from allele imbalance
    os.system('cat %s/fragment.read.file >%s/fragment.all.file'%(outdir, outdir))   

    # the order to phase with only ngs data.
    order='%s/../bin/SpecHap/build/SpecHap --ncs --protocols ngs,matrix --weights %s,%s --window_size 15000 --vcf %s --frag %s/fragment.sorted.file,%s/fragment.imbalance.file --out \
    %s/%s.specHap.phased.vcf'%(sys.path[0], 1-args.weight_imb, args.weight_imb, gene_vcf, outdir,outdir, outdir,gene)
    print (order)

    # integrate phase info from pacbio data if provided.
    if args.tgs != 'NA':

        command = """
        fq=%s
        outdir=%s
        bin=%s/../bin
        gene=%s
        ref=%s
        sample=pacbio

        $bin/pbmm2 align -j %s $ref $outdir/%s/$gene.pacbio.fq.gz $outdir/$sample.tgs.sort.bam --sort --sample $sample --rg '@RG\tID:movie1'
        $bin/ExtractHAIRs --triallelic 1 --pacbio 1 --indels 1 --ref $ref --bam $outdir/$sample.tgs.sort.bam --VCF %s --out $outdir/fragment.$sample.file
        cat $outdir/fragment.$sample.file >> $outdir/fragment.all.file
        """%(args.tgs, outdir, sys.path[0], gene.split("_")[1], hla_ref, args.thread_num, args.sample_id, gene_vcf)

        print ('extract linkage info from pacbio data.')
        os.system(command)
        # order = '%s/../bin/SpecHap/build/SpecHap --ncs -P --window_size 15000 --vcf %s --frag %s/fragment.sorted.file \
        # --out %s/%s.specHap.phased.vcf'%(sys.path[0],gene_vcf, outdir, outdir,gene)
        order += " -P"

    # nanopore
    if args.nanopore != 'NA':
        command = """
        fq=%s
        ref=%s
        outdir=%s
        bin=%s/../bin
        gene=%s
        sample=nanopore
        $bin/minimap2 -t %s -a $ref $outdir/%s/$gene.nanopore.fq.gz > $outdir/$sample.tgs.sam
        $bin/samtools view -F 2308 -b -T $ref $outdir/$sample.tgs.sam > $outdir/$sample.tgs.bam
        $bin/samtools sort $outdir/$sample.tgs.bam -o $outdir/$sample.tgs.sort.bam
        $bin/ExtractHAIRs --triallelic 1 --ONT 1 --indels 1 --ref $ref --bam $outdir/$sample.tgs.sort.bam --VCF %s --out $outdir/fragment.nanopore.file
        cat $outdir/fragment.nanopore.file >> $outdir/fragment.all.file
        """%(args.nanopore, hla_ref, outdir, sys.path[0], gene.split("_")[1], args.thread_num, args.sample_id, gene_vcf)
        print ('extract linkage info from nanopore TGS data.')
        os.system(command)
        # order = '%s/../bin/SpecHap/build/SpecHap --ncs -N --window_size 15000 --vcf %s --frag %s/fragment.sorted.file \
        # --out %s/%s.specHap.phased.vcf'%(sys.path[0],gene_vcf, outdir, outdir,gene)
        order += " -N"

    # hic 
    if args.hic_fwd != 'NA' and args.hic_rev != 'NA':
        command = """
        fwd_hic=%s
        rev_hic=%s
        ref=%s
        outdir=%s
        bin=%s/../bin
        sample=HiC
        group='@RG\tID:'$sample'\tSM:'$sample
        $bin/bwa mem -t %s -5SP -Y -U 10000 -L 10000,10000 -O 7,7 -E 2,2 $ref $fwd_hic $rev_hic >$outdir/$sample.tgs.raw.sam
        cat $outdir/$sample.tgs.raw.sam|grep -v 'XA:'|grep -v 'SA:'>$outdir/$sample.tgs.sam
        $bin/samtools view -F 2308 -b -T $ref $outdir/$sample.tgs.sam > $outdir/$sample.tgs.bam
        $bin/samtools sort $outdir/$sample.tgs.bam -o $outdir/$sample.tgs.sort.bam
        $bin/ExtractHAIRs --new_format 1 --triallelic 1 --hic 1 --indels 1 --ref $ref --bam $outdir/$sample.tgs.sort.bam --VCF %s --out $outdir/fragment.hic.file
        # python %s/whole/edit_linkage_value.py $outdir/fragment.raw.hic.file 10 $outdir/fragment.hic.file
        # rm $outdir/fragment.hic.file
        # touch $outdir/fragment.hic.file
        """%(args.hic_fwd, args.hic_rev, hla_ref, outdir, sys.path[0], args.thread_num, gene_vcf, sys.path[0])
        print ('extract linkage info from HiC data.')
        os.system(command)
        os.system('cat %s/fragment.hic.file >> %s/fragment.all.file'%(outdir, outdir))
        # order = '%s/../bin/SpecHap/build/SpecHap --ncs -H --new_format --window_size 15000 --vcf %s --frag %s/fragment.sorted.file \
        # --out %s/%s.specHap.phased.vcf'%(sys.path[0],gene_vcf, outdir, outdir,gene)
        order += " -H --new_format"

    # 10x genomics
    if args.tenx != 'NA':
        command = """
            fq=%s
            ref=%s
            outdir=%s
            bin=%s/../bin
            sample=%s
            gene=%s
            vcf=%s
            folder_name=tenx_bam_$sample
            bam=./$folder_name/outs/possorted_bam.bam
            
            if [ $gene == "HLA_A" ];
            then
                rm -rf ./$folder_name
                longranger align --id=$folder_name --fastqs=$fq --reference=%s/../db/ref/refdata-hla.ref.extend\
                    --sample=$sample --localcores=%s --localmem=10 
            fi
 
            $bin/ExtractHAIRs --new_format 1 --triallelic 1 --10X 1 --indels 1 --ref $ref --bam $bam\
                 --VCF $vcf --out $outdir/fragment.raw.tenx.file
            gzip -f -d -k $vcf
            %s/../spechla_env/bin/python3 %s/link_fragment.py -b $bam -f $outdir/fragment.raw.tenx.file\
                 -v %s -o  $outdir/fragment.raw3.tenx.file
            awk '$0=$0" 1"' $outdir/fragment.raw3.tenx.file >$outdir/fragment.tenx.file
            cat $outdir/fragment.tenx.file >> $outdir/fragment.all.file
        
        """%(args.tenx, hla_ref, outdir, sys.path[0], args.sample_id, gene, gene_vcf,sys.path[0], args.thread_num, sys.path[0],sys.path[0], gene_vcf[:-3])
        print ('align linked-reads with longranger and extract linkage info')
        os.system(command)
        
        # order = '%s/../bin/SpecHap/build/SpecHap --ncs -T  --new_format --window_size 15000 \
        # --vcf %s --frag %s/fragment.sorted.file\
        # --out %s/%s.specHap.phased.vcf'%(sys.path[0],gene_vcf, outdir, outdir,gene)
        order += " -T --new_format"

    if new_formate:
        os.system('sort -n -k6 %s/fragment.all.file >%s/fragment.sorted.file'%(outdir, outdir))
    else:
        os.system('sort -n -k3 %s/fragment.all.file >%s/fragment.sorted.file'%(outdir, outdir))

    os.system(order)
    
def all_poss_block_link():
    """
    if exon typing, to link block, we get all of possibilities
    of block linkage, and generate different fasta files.
    we then map the fasta to the allele database.
    we choose the linkage with highest mapping score.
    This function generates all possible fasta files.
    """
    block_intervals = []
    start = 0
    for pos in block_boundaries:
        block_intervals.append([start, pos])
        start = pos + 1
    block_intervals.append([start, 100000])
    all_poss = poss_link(len(block_intervals))
    print ("Num of all possible haps is %s."%(len(all_poss)))
    if len(all_poss) > 512:
        print ("ERROR: Too many blocks, the phasing process must be wrong.")
        print ("-----------------------------------------------------------")
        sys.exit(1)
    record_all_block_haps = []
    os.system("rm -f %s/%s.*.*.fasta"%(outdir, gene))
    for i in range(len(all_poss)):
        # print (all_poss[i], rephase_vcf)
        record_block_haps = []
        for j in range(len(block_intervals)):
            record_block_haps.append(block_intervals[j] + [all_poss[i][j]] )
        record_all_block_haps.append(record_block_haps)
        # generate rephased vcf and fasta for each possibility
        update_seqlist = block_phase(outdir,seq_list,snp_list,gene,gene_vcf,rephase_vcf,record_block_haps) 
        vcf2fasta(rephase_vcf)
        for z in range(1, 3):
            fasta = "%s/hla.allele.%s.%s.fasta"%(outdir, z, gene)
            # poss_fasta = "%s/hla.allele.raw.%s.%s.%s.fasta"%(outdir, i, z, gene)
            poss_fasta = "%s/%s.%s.%s.fasta"%(outdir, gene, i, z)
            # os.system("cp %s/hla.allele.%s.%s.fasta %s/hla.allele.raw.%s.%s.%s.fasta"%(outdir, z, gene, outdir, i, z, gene))
            sequence = read_fasta(fasta)
            out_f = open(poss_fasta, "w") # save all possible fastas
            print (">%s"%(gene), file = out_f)
            print (sequence, file = out_f)
            out_f.close()
    selected_poss_index = select_poss()
    print ("Selected combination is ", selected_poss_index)
    record_block_haps = record_all_block_haps[selected_poss_index]
    update_seqlist = block_phase(outdir,seq_list,snp_list,gene,gene_vcf,rephase_vcf,record_block_haps) 
    return update_seqlist

def select_poss():
    # map all possible haps to allele database
    # select the hap with highest mapping score
    reph='perl %s/whole/select.combination.pl -g %s -i %s -s %s -p Unknown'%(sys.path[0],gene,outdir,args.sample_id)        
    os.system(str(reph))    
    selected_fasta = "%s/result.%s.fasta"%(outdir, gene)
    f = open(selected_fasta, 'r')
    first_line = f.readline()
    array = first_line.strip().split(".")
    selected_poss_index = int(array[1])
    f.close()
    return selected_poss_index

def poss_link(block_num):
    # generate all possible linkage of blocks
    mytable=[]
    for j in range(2):
        mytable.append([j])
    if block_num>1:
        for i in range(block_num-1):
            double_table=[]
            for j in range(2):
                add_allele=[]
                for list in mytable:
                    newlist=list[:]
                    newlist.append(j)
                    add_allele.append(newlist)
                double_table+=add_allele
            mytable=double_table
    num = len(mytable)
    return mytable[:int(num/2)] 

def link_blocks():
    """
    Phasing unlinked blocks guided by HLA database
    """
    # link phase blocks with database
    print ('Start link blocks with database...')
    # map the haps in each block to the database
    
    if args.focus_exon_flag == 1:
        # Ergodic method for exon phasing
        update_seqlist = all_poss_block_link()
    else:
        if args.use_database == True:
            reph='%s/../spechla_env/bin/python3 %s/whole/map_block2_database.py %s %s'%(sys.path[0],sys.path[0],gene,outdir)     
            os.system(str(reph))
            # phase block with spectral graph theory
            print ("phase block with spectral graph theory")
            spec_block = "%s/../spechla_env/bin/python3 %s/phase_unlinked_block.py %s/%s_break_points_score.txt %s/%s_break_points_phased.txt"\
                %(sys.path[0],sys.path[0],outdir,gene,outdir,gene)
            os.system(str(spec_block))       
            record_block_haps = read_block_hap()
        else:
            # don't use database to link blocks
            # just for test and evaluation
            print ("skip phasing with blocks.")
            record_block_haps = []
        # refine the haplotype
        update_seqlist = block_phase(outdir,seq_list,snp_list,gene,gene_vcf,rephase_vcf,record_block_haps)  
    return update_seqlist

def get_mask_region():
    mask_dict = {}
    with open("%s/mask_dict.pkl"%(outdir), 'rb') as f:
        mask_dict = pickle.load(f) # gene: [mask_intervals]
    return mask_dict

def get_mask_reference():   
    mask_dict = get_mask_region()
    gene_mask_intervals = mask_dict[gene]
    # return the sequence saved in fasta file
    flag = False
    seq=''
    for line in open(hla_ref, 'r'):
        line=line.strip()
        if line[0] == '>':
            if line[1:] == gene:
                flag = True
            else:
                flag = False
            continue
        if flag:    
            seq+=line
    for mask in gene_mask_intervals:
        start = mask[0]
        end = mask[1]
        mask_len = end - start
        seq = seq[:start] + "N"*mask_len + seq[end:]
    f = open(mask_hla_ref, "w")
    print (">%s\n"%(gene)+seq, file = f)
    f.close()
    
def skip_mask_region(mask_dict, gene, start, end): 
    # not using
    gene_mask_intervals = mask_dict[gene]
    for mask in gene_mask_intervals:
        if start > mask[0] and start < mask[1]:
            start = mask[1]
        if end > mask[0] and end < mask[1]:
            end = mask[0]  
    return start, end    

def vcf2fasta(rephase_vcf):
    exon_bed = "%s/whole/exon_extent.bed"%(sys.path[0])
    exon_intervals = []
    f = open(exon_bed, 'r')
    for line in f:
        array = line.strip().split()
        if array[0] == gene:
            start = int(array[1])
            end = int(array[2])
            exon_intervals.append([start, end]) 
    f.close()

    j = 0
    for interval in exon_intervals:
        start, end = interval[0], interval[1]
        for i in range(1, 3):
            if j == 0:
                fastq2 = '%s/../bin/samtools faidx %s %s:%s-%s | %s/../bin/bcftools consensus -H %s --mask %s %s\
                    >%s/hla.allele.%s.%s.fasta'%(sys.path[0], hla_ref, gene, start, end, sys.path[0], i, mask_bed,\
                    rephase_vcf, outdir, i, gene)
            else:
                fastq2 = '%s/../bin/samtools faidx %s %s:%s-%s | %s/../bin/bcftools consensus -H %s --mask %s %s\
                    >>%s/hla.allele.%s.%s.fasta'%(sys.path[0], hla_ref, gene, start, end, sys.path[0], i, mask_bed, \
                    rephase_vcf, outdir, i, gene)              
            os.system(fastq2)
        j += 1

class Pedigree():

    def __init__(self):
        self.root_dir = "/".join(outdir.split("/")[:-1]) 
        self.sample_list = []

    def generate_ped_file(self): # get config file to run pedhap
        sample_list = args.trio.split(':')
        ped = '%s/%s/trio.ped'%(self.root_dir, sample_list[0])
        f = open(ped, 'w')
        if len(sample_list) == 3:
            content = """0 %s %s %s 0 1\n0 %s 0 0 2 1\n0 %s 0 0 1 1"""%(sample_list[0], sample_list[2], sample_list[1], sample_list[1], sample_list[2])
        else:
            print ('The trio info is incorrect.')
        print (content, end='',file = f)
        f.close()
        self.sample_list = sample_list  
        print (self.sample_list, gene, self.root_dir)

    def pedhap(self): # run pedhap
        command = """
        bin=%s/../bin/
        workdir=%s
        gene=%s
        child=%s
        mother=%s
        father=%s
        $bin/bcftools merge $workdir/$child/$gene.specHap.phased.refined.vcf.gz $workdir/$mother/$gene.specHap.phased.refined.vcf.gz $workdir/$father/$gene.specHap.phased.refined.vcf.gz -o $workdir/$child/$gene.trio.merge.vcf.gz -Oz -0
        tabix -f $workdir/$child/$gene.trio.merge.vcf.gz
        %s/../spechla_env/bin/python3 %s/pedhap/main.py --threshold1 0.6 --threshold2 0 -v $workdir/$child/$gene.trio.merge.vcf.gz -p $workdir/$child/trio.ped -o $workdir/$child/$gene.trio.rephase.vcf.gz
        file=$workdir/$child/$gene.trio.rephase.vcf.gz
        tabix -f $file
        for sample in `$bin/bcftools query -l $file`; do
            $bin/bcftools view -c1 -Oz -s $sample -o $workdir/$sample/trio/$sample.$gene.trio.vcf.gz $file
            tabix -f $workdir/$sample/trio/$sample.$gene.trio.vcf.gz
        done        
        """%(sys.path[0],self.root_dir, gene, self.sample_list[0], self.sample_list[1], self.sample_list[2], sys.path[0],sys.path[0])
        os.system(command)  
        print ("pedhap is done")  

    def refine_vcf(self):
        for sample in self.sample_list:
            trio_dir =  self.root_dir + '/' + sample + "/trio/"
            if not os.path.isdir(trio_dir):
                os.system('mkdir %s'%(trio_dir))
            raw = f"{self.root_dir}/{sample}/{gene}.specHap.phased.vcf"
            new = f"{self.root_dir}/{sample}/{gene}.specHap.phased.refined.vcf"

            if not os.path.isfile(raw):# no hete variants
                os.system(f"zcat {self.root_dir}/{sample}/{gene}.rephase.vcf.gz >{raw}")

            self.remove_conflicts(raw, new, sample)

            command = f"""
            bgzip -f {new}
            tabix -f {new}.gz
            """
            os.system(command)
           
    def remove_conflicts(self, raw, new, sample):
        # there might be conflicts when we merge vcf files
        # refine the vcf to avoid conflicts
        out_f = open(new, 'w')
        for line in open(raw):
            line = line.strip()
            if line[0] == "#":
                # if re.search("INFO=<ID=DP", line):
                #     line = line.replace("Number=1", "Number=1")
                if re.search("FORMAT=<ID=AD", line):
                    line = line.replace("Number=R", "Number=.")
                if re.search("FORMAT=<ID=AO", line):
                    line = line.replace("Number=A", "Number=.")
                if re.search("FORMAT=<ID=QA", line):
                    line = line.replace("Number=A", "Number=.")
                if re.search("INFO=<ID=CIGAR", line):
                    line = line.replace("Number=A", "Number=.")
                print (line, file = out_f)
            else:
                print (line, file = out_f)
        out_f.close()


    def main(self):
        self.generate_ped_file()
        self.refine_vcf()
        self.pedhap()
        print ("pedigree phasing is done.")


if __name__ == "__main__":   
    if len(sys.argv)==1:
        print (Usage%{'prog':sys.argv[0]})
    else:     
        bamfile,outdir,snp_dp,indel_len,freq_bias=args.bamfile,args.outdir,args.snp_dp,args.indel_len,args.freq_bias           
        snp_qual,gene,fq1,fq2,vcffile,long_indel_file = args.snp_qual,args.gene,args.fq1,args.fq2,args.vcf,args.sv
        strainsNum = 2 # two hap for each sample
        hla_ref = '%s/../db/ref/hla.ref.extend.fa'%(sys.path[0])
        mask_bed = "%s/low_depth.bed"%(outdir)
        gene_vcf = "%s/%s.vcf.gz"%(outdir, gene) # gene-specific variants 
        raw_spec_vcf = '%s/%s.specHap.phased.vcf'%(outdir,gene)
        spec_vcf = outdir + '/%s.spechap.vcf.gz'%(gene)
        rephase_vcf = '%s/%s.rephase.vcf.gz'%(outdir,gene)
        if not os.path.exists(outdir):
            os.system('mkdir '+ outdir) 
        new_formate = False  # different para for ExtractHAIRs
        # if we have 10x or hic data, use new formate for linkage info
        # required by SpecHap
        if args.hic_fwd != 'NA' or args.tenx != 'NA':
            new_formate = True    

        # read long Indels
        deletion_region, ins_seq = get_deletion_region(long_indel_file, gene)       
        # read small variants
        snp_list,beta_set,snp_index_dict = read_vcf(vcffile,outdir,snp_dp,bamfile,indel_len,gene,\
            freq_bias,strainsNum,deletion_region,snp_qual,gene_vcf)  

        
        if len(snp_list)==0:
            print ('No heterozygous locus, no need to phase.')
            gene_profile = no_snv_gene_phased(outdir, gene)
            os.system("cp %s %s"%(gene_vcf, rephase_vcf)) # get the phase result directly
            os.system('tabix -f %s'%(rephase_vcf))
        else:  
            # phase small variants          
            run_SpecHap()
            # if trio is offorded, use pedigree to refine phasing
            if args.trio != "None":
                if os.path.isfile("%s/%s.specHap.phased.vcf"%(outdir, gene)):
                    ped = Pedigree()
                    ped.main()
                    # raw_spec_vcf = outdir + '/trio/%s.%s.pedhap.trio.vcf.gz'%(args.sample_id, gene)
                    raw_spec_vcf = outdir + '/trio/%s.%s.trio.vcf.gz'%(args.sample_id, gene)
                else:
                    print ("## We should perform SpecHLA on the trio samples first, and reperfrom SpecHLA with trio info.")

            # found blcok boundaries from phased vcf of Spechap
            block_boundaries = get_unphased_loci(outdir, gene, raw_spec_vcf, snp_list, spec_vcf)
            seq_list = read_spechap_seq(spec_vcf, snp_list) # the haplotype obtained from SpecHap 
            # phase unlinked blocks
            update_seqlist = link_blocks()          
            # compute haplotype frequency with least-square
            fresh_alpha = compute_allele_frequency(update_seqlist, beta_set) 
            # output haplotype frequencies
            freq_output(outdir, gene, fresh_alpha, len(snp_list))
            # get the phase info to phase long Indel later
            gene_profile = gene_phased(update_seqlist,snp_list,gene)
            print ('Small variant-phasing of %s is done! Haplotype ratio is %s:%s'%(gene, fresh_alpha[0], fresh_alpha[1]))

        if args.focus_exon_flag == 1:
            vcf2fasta(rephase_vcf)
        else:
            # realign reads to the modified reference generated by combining long 
            # insertion sequence and the original reference
            ins_seq = get_insertion_linkage(ins_seq)
            # get copy number of long Indels
            deletion_region = get_copy_number(outdir, deletion_region, gene, ins_seq) 

            if gene == 'HLA_DRB1':
                # DRB1 contains long duplicates in the region 3900-4400 bp
                # Infer the sequence in this region
                dup_region_type(outdir, strainsNum, bamfile)
                dup_file = outdir +'/select.DRB1.seq.txt'

            if len(ins_seq) > 0:
                # after map reads to the long insertion sequence
                # there can be hete variants
                # get consensus sequence if copy number is 1 
                # phase the variants to get two haps if copy number is 2
                phase_insertion(gene, outdir, args.ref, sys.path[0])

            # phase long indels
            sh = Share_reads(deletion_region, outdir, strainsNum, gene, gene_profile, ins_seq)
            sh.split_seg()
        print ('Phasing of %s is done!\n\n'%(gene))


